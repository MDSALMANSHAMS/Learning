{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853cdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "### 1. Input\n",
    "You give an **image** (say, 224x224x3 RGB image) as input.  \n",
    "The network sees **pixels as numbers** â€” not as actual images.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Convolutional Layer\n",
    "- A small **filter (kernel)** (say 3x3 or 5x5) **slides** over the image.\n",
    "\n",
    "Purpose:  \n",
    "ðŸ”¹ Detect **features** (edges, textures, corners)  \n",
    "ðŸ”¹ Filters are **learned automatically** during training.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Activation Function (e.g., ReLU)\n",
    "After convolution output, apply an activation like:\n",
    "\n",
    "It **introduces non-linearity**, so CNN can learn complex mappings (not just linear transformations).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Pooling Layer (Downsampling)\n",
    "Purpose:  \n",
    "ðŸ”¹ Make model **translation invariant**  \n",
    "ðŸ”¹ **Reduce computation** and prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Stack Layers\n",
    "Repeat multiple **conv â†’ activation â†’ pooling** blocks.\n",
    "- Early layers learn **edges**, **textures**.\n",
    "- Deeper layers learn **complex shapes**, **objects**.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Flattening\n",
    "- After several convolution + pooling layers, you get a small **3D tensor**.\n",
    "- **Flatten** it into a **1D vector** to feed into a **Fully Connected (FC) Layer**.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Fully Connected Layer(s)\n",
    "- Normal dense layers.\n",
    "- Perform classification or regression depending on the task.\n",
    "- Often end with a **Softmax activation** for multiclass classification.\n",
    "\n",
    "we use Softmax to output **probabilities** for each class.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Loss Function\n",
    "- Compute **loss** (e.g., Cross-Entropy Loss for classification):\n",
    "Loss = -\\sum y_true*log(y_pred)\n",
    "\n",
    "---\n",
    "\n",
    "### 9. Backpropagation\n",
    "- Gradients of loss w.r.t parameters are calculated using **chain rule**.\n",
    "- Update filter weights and FC layer weights via **Gradient Descent** (or its variants like Adam).\n",
    "\n",
    "\n",
    "## CNN is good for images because:\n",
    "- It captures **spatial hierarchy** (local to global features).\n",
    "- It has **few parameters** compared to fully connected layers (filters are shared across locations).\n",
    "- **Translation invariance** (small movements don't affect prediction).\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a8c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
